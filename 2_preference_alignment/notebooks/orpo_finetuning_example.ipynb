{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiXt8OQoNEyO"
      },
      "source": [
        "# Preference Alignment with Odds Ratio Preference Optimization (ORPO)\n",
        "\n",
        "This notebook will guide you through the process of fine-tuning a language model using Odds Ratio Preference Optimization (ORPO). We will use the SmolLM2-135M model which has **not** been through SFT training, so it is not compatible with DPO. This means, you cannot use the model you trained in [1_instruction_tuning](../../1_instruction_tuning/notebooks/sft_finetuning_example.ipynb).\n",
        "\n",
        "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
        "     <h2 style='margin: 0;color:blue'>Exercise: Aligning SmolLM2 with ORPOTrainer</h2>\n",
        "     <p>Take a dataset from the Hugging Face hub and align a model on it. </p>\n",
        "     <p><b>Difficulty Levels</b></p>\n",
        "     <p>üê¢ Use the `trl-lib/ultrafeedback_binarized` dataset</p>\n",
        "     <p>üêï Try out the `argilla/ultrafeedback-binarized-preferences` dataset</p>\n",
        "     <p>ü¶Å Try on a subset of mlabonne's `orpo-dpo-mix-40k` dataset</p>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3eEUpQcNEyQ"
      },
      "source": [
        "## Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwNxh0pCQhfI",
        "outputId": "e4c288e1-2fa3-4717-d9dd-ae3ec0b91e3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ben/code/smol-course/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        ")\n",
        "from trl import ORPOConfig, ORPOTrainer, setup_chat_format\n",
        "\n",
        "# Authenticate to Hugging Face\n",
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY1Qs3YTNEyR"
      },
      "source": [
        "## Format dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KqjOeTPNEyR",
        "outputId": "60bba802-9cce-43fd-fd73-c492223e1142"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62135/62135 [00:00<00:00, 450465.27 examples/s]\n",
            "Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 382866.64 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "\n",
        "# TODO: ü¶Åüêï change the dataset to one of your choosing\n",
        "dataset = load_dataset(path=\"trl-lib/ultrafeedback_binarized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BI90JN6NEyS"
      },
      "outputs": [],
      "source": [
        "# TODO: üêï If your dataset is not represented as conversation lists, you can use the `process_dataset` function to convert it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzFhcq5LNEyS"
      },
      "source": [
        "## Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2kGBNStQoUd"
      },
      "outputs": [],
      "source": [
        "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Model to fine-tune\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    pretrained_model_name_or_path=model_name,\n",
        "    torch_dtype=torch.float32,\n",
        ").to(device)\n",
        "model.config.use_cache = False\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model, tokenizer = setup_chat_format(model, tokenizer)\n",
        "\n",
        "# Set our name for the finetune to be saved &/ uploaded to\n",
        "finetune_name = \"SmolLM2-FT-ORPO\"\n",
        "finetune_tags = [\"smol-course\", \"module_1\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP88StDbNEyS"
      },
      "source": [
        "## Train model with ORPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWDwJe7_Qqgb"
      },
      "outputs": [],
      "source": [
        "orpo_args = ORPOConfig(\n",
        "    # Small learning rate to prevent catastrophic forgetting\n",
        "    learning_rate=8e-6,\n",
        "    # Linear learning rate decay over training\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    # Maximum combined length of prompt + completion\n",
        "    max_length=1024,\n",
        "    # Maximum length for input prompts\n",
        "    max_prompt_length=512,\n",
        "    # Controls weight of the odds ratio loss (Œª in paper)\n",
        "    beta=0.1,\n",
        "    # Batch size for training\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    # Helps with training stability by accumulating gradients before updating\n",
        "    gradient_accumulation_steps=4,\n",
        "    # Memory-efficient optimizer for CUDA, falls back to adamw_torch for CPU/MPS\n",
        "    optim=\"paged_adamw_8bit\" if device == \"cuda\" else \"adamw_torch\",\n",
        "    # Number of training epochs\n",
        "    num_train_epochs=1,\n",
        "    # When to run evaluation\n",
        "    # FIXED: evaluation_strategy to eval_strategy\n",
        "    eval_strategy=\"steps\",\n",
        "    # Evaluate every 20% of training\n",
        "    eval_steps=0.2,\n",
        "    # Log metrics every step\n",
        "    logging_steps=1,\n",
        "    # Gradual learning rate warmup\n",
        "    warmup_steps=10,\n",
        "    # Disable external logging\n",
        "    report_to=\"none\",\n",
        "    # Where to save model/checkpoints\n",
        "    output_dir=\"./results/\",\n",
        "    # Enable MPS (Metal Performance Shaders) if available\n",
        "    use_mps_device=device == \"mps\",\n",
        "    hub_model_id=finetune_name,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0GfkrByNEyT"
      },
      "outputs": [],
      "source": [
        "trainer = ORPOTrainer(\n",
        "    model=model,\n",
        "    args=orpo_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr_SWRmeNEyT"
      },
      "outputs": [],
      "source": [
        "trainer.train()  # Train the model\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(f\"./{finetune_name}\")\n",
        "\n",
        "# Save to the huggingface hub if login (HF_TOKEN is set)\n",
        "if os.getenv(\"HF_TOKEN\"):\n",
        "    trainer.push_to_hub(tags=finetune_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEmo3nDNEyT"
      },
      "source": [
        "## üíê You're done!\n",
        "\n",
        "This notebook provided a step-by-step guide to fine-tuning the `HuggingFaceTB/SmolLM2-135M` model using the `ORPOTrainer`. By following these steps, you can adapt the model to perform specific tasks more effectively. If you want to carry on working on this course, here are steps you could try out:\n",
        "\n",
        "- Try this notebook on a harder difficulty\n",
        "- Review a colleagues PR\n",
        "- Improve the course material via an Issue or PR."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}